{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636eb8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "H-DRIFT-M Quality Gate (Binary Classifier): good (x1) vs bad (x2)\n",
    "\n",
    "Goal:\n",
    "- Train a model that maps an image I -> y in {0,1}\n",
    "  1 = good quality (x1)\n",
    "  0 = bad quality / drifting (x2)\n",
    "\n",
    "Why:\n",
    "- Acts as a supervisory quality gate:\n",
    "  - If bad: trigger re-focus / illumination check / pause / alert\n",
    "  - If good: continue acquisition\n",
    "\n",
    "Dataset layout (recommended):\n",
    "data/\n",
    "  train/\n",
    "    good/   (x1 images)\n",
    "    bad/    (x2 images)\n",
    "  val/\n",
    "    good/\n",
    "    bad/\n",
    "  test/\n",
    "    good/\n",
    "    bad/\n",
    "\n",
    "Usage:\n",
    "  python train_quality_gate.py --data_dir data --epochs 20 --model resnet18\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22e1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd32689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Reproducibility utilities\n",
    "# --------------------------\n",
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c531c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# MUSE-like degradations\n",
    "# --------------------------\n",
    "class RandomDefocus:\n",
    "    \"\"\"Simulates focus drift by applying Gaussian blur with random sigma.\"\"\"\n",
    "    def __init__(self, p: float = 0.4, sigma_range: Tuple[float, float] = (0.3, 2.0)):\n",
    "        self.p = p\n",
    "        self.sigma_range = sigma_range\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > self.p:\n",
    "            return img\n",
    "        sigma = random.uniform(*self.sigma_range)\n",
    "        # torchvision GaussianBlur expects kernel_size odd and sigma can be float\n",
    "        blur = transforms.GaussianBlur(kernel_size=9, sigma=sigma)\n",
    "        return blur(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "808855a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomIlluminationBias:\n",
    "    \"\"\"\n",
    "    Simulates illumination decay/bias:\n",
    "    - random brightness scaling\n",
    "    - random gamma adjustment\n",
    "    - optional vignetting-like effect (approx)\n",
    "    \"\"\"\n",
    "    def __init__(self, p: float = 0.5, brightness=(0.6, 1.2), gamma=(0.7, 1.5)):\n",
    "        self.p = p\n",
    "        self.brightness = brightness\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > self.p:\n",
    "            return img\n",
    "\n",
    "        # brightness scale\n",
    "        b = random.uniform(*self.brightness)\n",
    "        img = transforms.functional.adjust_brightness(img, b)\n",
    "\n",
    "        # gamma\n",
    "        g = random.uniform(*self.gamma)\n",
    "        img = transforms.functional.adjust_gamma(img, g)\n",
    "\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3045ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomKnifeArtifacts:\n",
    "    \"\"\"\n",
    "    Simulates knife/tissue surface artifacts:\n",
    "    - random thin streaks (scratches)\n",
    "    - random contrast reduction\n",
    "    NOTE: This is a proxy; real knife artifacts are more complex.\n",
    "    \"\"\"\n",
    "    def __init__(self, p: float = 0.35):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Convert to tensor to inject simple streak-like artifacts\n",
    "        t = transforms.functional.pil_to_tensor(img).float() / 255.0  # [C,H,W]\n",
    "        c, h, w = t.shape\n",
    "\n",
    "        # Add a few random streaks\n",
    "        num_lines = random.randint(1, 5)\n",
    "        for _ in range(num_lines):\n",
    "            y = random.randint(0, h - 1)\n",
    "            thickness = random.randint(1, 3)\n",
    "            intensity = random.uniform(0.05, 0.25)\n",
    "            y0 = max(0, y - thickness)\n",
    "            y1 = min(h, y + thickness)\n",
    "            t[:, y0:y1, :] = torch.clamp(t[:, y0:y1, :] + intensity, 0.0, 1.0)\n",
    "\n",
    "        # Slight contrast reduction (mimic surface degradation)\n",
    "        t = (t - 0.5) * random.uniform(0.6, 0.95) + 0.5\n",
    "        t = torch.clamp(t, 0.0, 1.0)\n",
    "\n",
    "        return transforms.functional.to_pil_image((t * 255.0).byte())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b305738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Config\n",
    "# --------------------------\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    data_dir: str\n",
    "    model_name: str = \"resnet18\"\n",
    "    image_size: int = 224\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 20\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    seed: int = 42\n",
    "    num_workers: int = 4\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_path: str = \"quality_gate_best.pt\"\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Model builder\n",
    "# --------------------------\n",
    "def build_model(model_name: str, num_classes: int = 2) -> nn.Module:\n",
    "    if model_name == \"resnet18\":\n",
    "        m = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "        return m\n",
    "    if model_name == \"resnet50\":\n",
    "        m = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "        return m\n",
    "    if model_name == \"vit_b_16\":\n",
    "        m = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
    "        m.heads.head = nn.Linear(m.heads.head.in_features, num_classes)\n",
    "        return m\n",
    "    raise ValueError(f\"Unknown model_name={model_name}. Use resnet18/resnet50/vit_b_16.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1580a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Metrics\n",
    "# --------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: str) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tp = fp = tn = fn = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "\n",
    "        # Assume label mapping: bad=0, good=1 (because folders alphabetical => bad, good)\n",
    "        tp += ((pred == 1) & (y == 1)).sum().item()\n",
    "        tn += ((pred == 0) & (y == 0)).sum().item()\n",
    "        fp += ((pred == 1) & (y == 0)).sum().item()\n",
    "        fn += ((pred == 0) & (y == 1)).sum().item()\n",
    "\n",
    "    acc = correct / max(total, 1)\n",
    "    precision = tp / max(tp + fp, 1)\n",
    "    recall = tp / max(tp + fn, 1)\n",
    "    f1 = 2 * precision * recall / max(precision + recall, 1e-12)\n",
    "\n",
    "    return {\"acc\": acc, \"precision_good\": precision, \"recall_good\": recall, \"f1_good\": f1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc992865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Training\n",
    "# --------------------------\n",
    "def main(cfg: TrainConfig) -> None:\n",
    "    seed_everything(cfg.seed)\n",
    "\n",
    "    train_dir = os.path.join(cfg.data_dir, \"train\")\n",
    "    val_dir = os.path.join(cfg.data_dir, \"val\")\n",
    "    test_dir = os.path.join(cfg.data_dir, \"test\")\n",
    "\n",
    "    # NOTE: ImageFolder assigns class indices alphabetically.\n",
    "    # If your folders are named: bad/, good/\n",
    "    # then class_to_idx will be {\"bad\": 0, \"good\": 1}\n",
    "    base_aug = [\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.1),\n",
    "        transforms.RandomApply([transforms.ColorJitter(contrast=0.2)], p=0.3),\n",
    "        RandomDefocus(p=0.35),\n",
    "        RandomIlluminationBias(p=0.4),\n",
    "        RandomKnifeArtifacts(p=0.25),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    "    train_tf = transforms.Compose(base_aug)\n",
    "\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n",
    "    val_ds = datasets.ImageFolder(val_dir, transform=val_tf)\n",
    "    test_ds = datasets.ImageFolder(test_dir, transform=val_tf)\n",
    "\n",
    "    print(\"Class mapping:\", train_ds.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1274aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Main training\n",
    "# -------------------------\n",
    "def main():\n",
    "    cfg = TrainConfig()\n",
    "    seed_everything()\n",
    "\n",
    "    # Transforms\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.GaussianBlur(kernel_size=9, sigma=(0.5, 3.0)),  # simulate defocus\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    # Datasets\n",
    "    train_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"train\"), transform=train_tf)\n",
    "    val_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"val\"), transform=val_tf)\n",
    "    test_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"test\"), transform=val_tf)\n",
    "\n",
    "    print(\"Class mapping:\", train_ds.class_to_idx)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f37fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Main training\n",
    "# -------------------------\n",
    "def main():\n",
    "    cfg = TrainConfig()\n",
    "    seed_everything()\n",
    "\n",
    "    # Transforms\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.GaussianBlur(kernel_size=9, sigma=(0.5, 3.0)),  # simulate defocus\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    # Datasets\n",
    "    train_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"train\"), transform=train_tf)\n",
    "    val_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"val\"), transform=val_tf)\n",
    "    test_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"test\"), transform=val_tf)\n",
    "\n",
    "    print(\"Class mapping:\", train_ds.class_to_idx)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c8d3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Model builder\n",
    "# -------------------------\n",
    "def build_model(model_name: str, num_classes: int = 2) -> nn.Module:\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError(\"Only resnet18 is supported in this script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "# -------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: str) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tp = fp = fn = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        tp += ((preds == 1) & (y == 1)).sum().item()\n",
    "        fp += ((preds == 1) & (y == 0)).sum().item()\n",
    "        fn += ((preds == 0) & (y == 1)).sum().item()\n",
    "\n",
    "    acc = correct / max(total, 1)\n",
    "    precision = tp / max(tp + fp, 1)\n",
    "    recall = tp / max(tp + fn, 1)\n",
    "    f1 = 2 * precision * recall / max(precision + recall, 1e-12)\n",
    "\n",
    "    return {\"acc\": acc, \"f1_good\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37b9472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Main training\n",
    "# -------------------------\n",
    "def main():\n",
    "    cfg = TrainConfig()\n",
    "    seed_everything()\n",
    "\n",
    "    # Transforms\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.GaussianBlur(kernel_size=9, sigma=(0.5, 3.0)),  # simulate defocus\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5b87723",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Datasets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_ds = datasets.ImageFolder(os.path.join(\u001b[43mcfg\u001b[49m.data_dir, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m), transform=train_tf)\n\u001b[32m      3\u001b[39m val_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m), transform=val_tf)\n\u001b[32m      4\u001b[39m test_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m), transform=val_tf)\n",
      "\u001b[31mNameError\u001b[39m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "    # Datasets\n",
    "    train_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"train\"), transform=train_tf)\n",
    "    val_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"val\"), transform=val_tf)\n",
    "    test_ds = datasets.ImageFolder(os.path.join(cfg.data_dir, \"test\"), transform=val_tf)\n",
    "\n",
    "    print(\"Class mapping:\", train_ds.class_to_idx)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Model\n",
    "    model = build_model(cfg.model_name, num_classes=2).to(cfg.device)\n",
    "\n",
    "    # Class weights (handle imbalance)\n",
    "    labels = [y for _, y in train_ds.samples]\n",
    "    counts = np.bincount(labels)\n",
    "    weights = counts.sum() / np.maximum(counts, 1)\n",
    "    class_weights = torch.tensor(weights, dtype=torch.float32, device=cfg.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs)\n",
    "\n",
    "    best_f1 = -1.0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(cfg.device), y.to(cfg.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * y.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        train_loss = running_loss / max(len(train_ds), 1)\n",
    "\n",
    "        val_metrics = evaluate(model, val_loader, cfg.device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d}/{cfg.epochs} | \"\n",
    "            f\"train_loss={train_loss:.4f} | \"\n",
    "            f\"val_acc={val_metrics['acc']:.4f} | \"\n",
    "            f\"val_f1_good={val_metrics['f1_good']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_metrics[\"f1_good\"] > best_f1:\n",
    "            best_f1 = val_metrics[\"f1_good\"]\n",
    "            torch.save(model.state_dict(), cfg.save_path)\n",
    "\n",
    "    print(\"Training complete. Best model saved to:\", cfg.save_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
